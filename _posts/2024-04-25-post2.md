# GPU Batch Size for Deep Learning
In my initial exploration of training deep learning models using fastai I experimented with varied batch sizes for training. I'd like to share my results as they were initially surprising and some information about batch size.

Content covered in this riveting post:

1. TOC
{:toc}

## What is batch size?

Batch size refers to the number of samples being provided to the model for training at a time. This has a direct impact on the time taken to train a model as well as the error rate of the model.

## My Training Results

| Batch Size | 16 | 32 | 64 | 128 | 256 |
|----|----|----|----|----|----|
| Time [s] | 11.4 | 9.3 | 16.4 | 19.6 | 40.3 |

## Why the strange trend?
Theoretically, the larger the batch size, the faster training time should be. However, in this case the GPU's 4GB memory was a limiting factor which did not allow the machine to effectively utilise larger batch sizes for training, this can be seen visually as the GPU memory demand greatly increases past 32 batch size. Another notable trend is that error rate is inversely proportional to batch size [1].

## Conclusion
Therefore, to determine an appropriate batch size for a deep learning application, one must balance their needs depending on desired training time and model accuracy.


## References
1. https://wandb.ai/ayush-thakur/dl-question-bank/reports/What-s-the-Optimal-Batch-Size-to-Train-a-Neural-Network---VmlldzoyMDkyNDU

